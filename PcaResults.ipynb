{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score,classification_report,confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv(\"X.csv\")\n",
    "y=pd.read_csv(\"Y.csv\")\n",
    "rifX=x\n",
    "rifY=y[\"RIF\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating features with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "rifConcatenated=pd.concat([rifX,rifY],axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2779\n",
       "True      614\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rifConcatenated.duplicated().value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping Duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2779, 223)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rifConcatenated=rifConcatenated.drop_duplicates()\n",
    "rifConcatenated.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of invalid labeled rows (label with -1 are invalid rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2725\n",
       "True       54\n",
       "Name: RIF, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rifConcatenated[\"RIF\"]==-1).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows with invalid labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 313,  320,  346,  360,  381,  395,  397,  398,  403,  808, 1373,\n",
       "            1586, 1588, 1706, 1715, 1717, 1800, 1857, 1902, 1945, 2190, 2355,\n",
       "            2383, 2429, 2630, 2899, 2932, 2935, 3078, 3099, 3100, 3103, 3106,\n",
       "            3109, 3112, 3118, 3125, 3128, 3131, 3135, 3139, 3155, 3189, 3214,\n",
       "            3221, 3229, 3235, 3240, 3241, 3242, 3246, 3258, 3259, 3261],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalidRows=rifConcatenated[rifConcatenated[\"RIF\"]==-1]\n",
    "invalidRows.index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping invalid labeled rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2725, 223)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rifFiltered=rifConcatenated.drop(invalidRows.index)\n",
    "rifFiltered.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "rifX=rifFiltered.iloc[:,0:222]\n",
    "rifY=rifFiltered.iloc[:,[222]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "rifX=rifX.replace(-1,0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1456\n",
      "0    1269\n",
      "Name: RIF, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts=rifFiltered['RIF'].value_counts()\n",
    "print(counts)\n",
    "proportions = counts / counts.sum()\n",
    "proportions=proportions*100\n",
    "sns.barplot(x=[\"Resistant\",\"Suspectible\"],y=proportions.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "rifX_train,rifX_test,rifY_train,rifY_test=train_test_split(rifX,rifY,test_size=0.2,random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chandra sekhar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "information_gain_scores=mutual_info_classif(rifX_train,rifY_train)\n",
    "information_gain_best_features_indices= information_gain_scores.argsort()[::-1][0:64]\n",
    "infomation_gain_train=rifX_train.iloc[:,information_gain_best_features_indices]\n",
    "infomation_gain_test=rifX_test.iloc[:,information_gain_best_features_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "selector=SelectKBest(chi2,k=64)\n",
    "chi_square_selected_features=selector.fit_transform(rifX_train,rifY_train)\n",
    "chi_square_selected_features.shape\n",
    "np.unique(selector.get_support(),return_counts=True)\n",
    "# print(selector.get_support())\n",
    "chi_square_train=rifX_train.iloc[:,selector.get_support()]\n",
    "chi_square_test=rifX_test.iloc[:,selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=64)\n",
    "rifX_pca=pca.fit_transform(rifX)\n",
    "pca_train,pca_test,pca_y_train,pca_y_test=train_test_split(rifX_pca,rifY,test_size=0.2,random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chandra sekhar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:488: FutureWarning: From version 1.3 whiten='unit-variance' will be used by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "ica=FastICA(n_components=64)\n",
    "rifX_ica=ica.fit_transform(rifX)\n",
    "ica_train,ica_test,ica_y_train,ica_y_test=train_test_split(rifX_pca,rifY,test_size=0.2,random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 706us/step\n",
      "18/18 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "input_data = Input(shape=(222,))\n",
    "encoded = Dense(64, activation='relu')(input_data)\n",
    "encoder = Model(input_data, encoded)\n",
    "auto_enconder_data_train = encoder.predict(rifX_train)\n",
    "\n",
    "input_data_t = Input(shape=(222,))\n",
    "encoded_t = Dense(64, activation='relu')(input_data_t)\n",
    "encoder_t = Model(input_data_t, encoded_t)\n",
    "auto_enconder_data_test = encoder_t.predict(rifX_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter tuning for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1=RandomForestClassifier()\n",
    "# param_grid = {\n",
    "#     'n_estimators': [30,50, 100],\n",
    "#     'max_depth': [None, 5, 10],\n",
    "# }\n",
    "# grid_search = GridSearchCV(model1, param_grid=param_grid, cv=5, n_jobs=-1,scoring='roc_auc',verbose=0)\n",
    "# grid_search.fit(rifX, rifY)\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter tuning for svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2=svm.SVC()\n",
    "# param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "# grid_search = GridSearchCV(model2, param_grid, refit=True, verbose=0, cv=5,scoring='roc_auc')\n",
    "# grid_search.fit(rifX, rifY)\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter tuning for BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model4=BernoulliNB()\n",
    "# param_grid = {'alpha': [0.1, 1, 10]}\n",
    "# grid_search = GridSearchCV(model4, param_grid=param_grid, cv=5,scoring='roc_auc',verbose=0)\n",
    "# grid_search.fit(rifX, rifY)\n",
    "# print(\"Best hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame({\"Algorithm\":[],\"Accuracy\":[],\"Precision\":[],\"F1 score\":[],\"Sensitivity\":[],\"Specificity\":[],\"AUC\":[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printResults(Algo,test_data,pred_data):\n",
    "    global results\n",
    "    print(Algo)\n",
    "    print(\"--------------------\")\n",
    "    accuracy=accuracy_score(test_data,pred_data)\n",
    "    F1_score=f1_score(test_data,pred_data)\n",
    "    auc=roc_auc_score(test_data,pred_data)\n",
    "    precision=precision_score(test_data,pred_data)\n",
    "    sensitivity=recall_score(test_data,pred_data)\n",
    "    specificity=1-sensitivity\n",
    "    print(\"accuracy \",accuracy ,end=\" , \")\n",
    "    print(\"f1_score \", F1_score,end=\" , \")\n",
    "    print(\"auc \", auc)\n",
    "    print(\"precision \",precision,end=\" , \")\n",
    "    print(\"sensitivity \",sensitivity,end=\" , \")\n",
    "    print(\"specificity \",1-sensitivity)\n",
    "    # temp=pd.DataFrame({\"Algorithm\":[Algo],\"Accuracy\":[accuracy],\"Precision\":[precision],\"F1 score\":[F1_score],\"Sensitivity\":[sensitivity],\"Specificity\":[specificity],\"AUC\":[auc]})\n",
    "    # print(temp)\n",
    "    # results=results.concat({\"Algorithm\":Algo,\"Accuracy\":accuracy,\"Precision\":precision,\"F1 score\":F1_score,\"Sensitivity\":sensitivity,\"Specificity\":specificity,\"AUC\":auc},ignore_index=True)\n",
    "    # ! temporary desable of confusion matrix\n",
    "    # cm=(confusion_matrix(test_data,pred_data))\n",
    "    # sns.heatmap(cm,annot=True,cmap=\"Blues\",fmt=\"d\")\n",
    "    # plt.title(\"Confusion Matrix\")\n",
    "    # plt.xlabel(\"Predicted Label\")\n",
    "    # plt.ylabel(\"Actual Label\")r\n",
    "    # plt.show()\n",
    "# accuracy  0.5009174311926605 , f1_score  0.6467532467532469 , auc  0.460477865968415\n",
    "# precision  0.5331905781584583 , sensitivity  0.8217821782178217 , specificity  0.17821782178217827"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customise this input variables with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X_train=pca_train\n",
    "input_X_test=pca_test\n",
    "input_Y_train=rifY_train\n",
    "input_Y_test=rifY_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2180, 222)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rifX_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2180, 64)\n",
      "(545, 64)\n"
     ]
    }
   ],
   "source": [
    "print(infomation_gain_train.shape)\n",
    "print(infomation_gain_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model1 (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chandra sekhar\\AppData\\Local\\Temp\\ipykernel_9840\\1159321004.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rifModel1.fit(input_X_train,rifY_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "--------------------\n",
      "accuracy  0.9247706422018349 , f1_score  0.930390492359932 , auc  0.9273518260917001\n",
      "precision  0.958041958041958 , sensitivity  0.9042904290429042 , specificity  0.09570957095709576\n"
     ]
    }
   ],
   "source": [
    "rifModel1=RandomForestClassifier(n_estimators=50,max_depth=5)\n",
    "rifModel1.fit(input_X_train,rifY_train)\n",
    "rifPred=rifModel1.predict(input_X_test)\n",
    "printResults(\"Random Forest\",rifY_test,rifPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest(auto encoders features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rifModel1=RandomForestClassifier(n_estimators=50,max_depth=5)\n",
    "# rifModel1.fit(auto_enconder_data_train,rifY_train)\n",
    "# rifPred=rifModel1.predict(auto_enconder_data_test)\n",
    "# printResults(\"Random Forest (auto encoder feature )\",rifY_test,rifPred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 2 (svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "--------------------\n",
      "accuracy  0.9596330275229358 , f1_score  0.9639344262295082 , auc  0.9582890107192537\n",
      "precision  0.9576547231270358 , sensitivity  0.9702970297029703 , specificity  0.02970297029702973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chandra sekhar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "rifModel2=svm.SVC(kernel=\"linear\",C= 0.1, gamma= 0.1)\n",
    "rifModel2.fit(rifX_train,rifY_train)\n",
    "rifPred=rifModel2.predict(rifX_test)\n",
    "printResults(\"SVM\",rifY_test,rifPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with Reduced_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rifModel2=svm.SVC(kernel=\"linear\",C= 0.1, gamma= 0.1)\n",
    "# rifModel2.fit(auto_enconder_data_train,rifY_train)\n",
    "# rifPred=rifModel2.predict(auto_enconder_data_test)\n",
    "# printResults(\"SVM (auto encoder features)\",rifY_test,rifPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm with infomation gain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rifModel2=svm.SVC(kernel=\"linear\",C= 0.1, gamma= 0.1)\n",
    "# rifModel2.fit(infomation_gain_train,rifY_train)\n",
    "# rifPred=rifModel2.predict(infomation_gain_test)\n",
    "# printResults(\"SVM (info gain features)\",rifY_test,rifPred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 3 (Logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "--------------------\n",
      "accuracy  0.9596330275229358 , f1_score  0.9638157894736842 , auc  0.9587049614052314\n",
      "precision  0.9606557377049181 , sensitivity  0.966996699669967 , specificity  0.03300330033003296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chandra sekhar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "rifModel3=LogisticRegression()\n",
    "rifModel3.fit(rifX_train,rifY_train)\n",
    "rifPred=rifModel3.predict(rifX_test)\n",
    "printResults(\"Logistic Regression\",rifY_test,rifPred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model4 (bernoulliNB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB\n",
      "--------------------\n",
      "accuracy  0.8935779816513761 , f1_score  0.9010238907849829 , auc  0.8963873660093281\n",
      "precision  0.9328621908127208 , sensitivity  0.8712871287128713 , specificity  0.12871287128712872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chandra sekhar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "rifModel4=BernoulliNB(alpha=10)\n",
    "rifModel4.fit(rifX_train,rifY_train)\n",
    "rifPred=rifModel4.predict(rifX_test)\n",
    "printResults(\"BernoulliNB\",rifY_test,rifPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chandra sekhar\\AppData\\Local\\Temp\\ipykernel_9840\\1301348187.py:14: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_classfier=KerasClassifier(build_fn=nnModel,verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step\n",
      "Neural Networks\n",
      "--------------------\n",
      "accuracy  0.9486238532110092 , f1_score  0.9512195121951219 , auc  0.9479208801876872\n",
      "precision  0.934931506849315 , sensitivity  0.9680851063829787 , specificity  0.03191489361702127\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(rifX, rifY, test_size=0.2, random_state=22)\n",
    "def nnModel(optimizer):\n",
    "    model = Sequential([\n",
    "    Dense(16, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dropout(0.4),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary output\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "keras_classfier=KerasClassifier(build_fn=nnModel,verbose=0)\n",
    "param_grid={\n",
    "    \"batch_size\":[16,32],\n",
    "    \"epochs\":[5,10,15],\n",
    "    \"optimizer\":[\"adam\",\"adagrad\",\"rmsprop\",\"sgd\"]\n",
    "}\n",
    "\n",
    "grid_search=GridSearchCV(estimator=keras_classfier,param_grid=param_grid,cv=5)\n",
    "grid_search.fit(X_train,Y_train)\n",
    "grid_search.best_params_\n",
    "grid_search.best_params_\n",
    "y_pred = grid_search.predict(X_test)\n",
    "y_pred_binary = np.round(y_pred)  # Convert probabilities to binary predictions\n",
    "\n",
    "printResults(\"Neural Networks\",Y_test,y_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 64, 1)]           0         \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 64, 32)            96        \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 64, 64)            4160      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1843 (Dense)          (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_1844 (Dense)          (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1845 (Dense)          (None, 16)                528       \n",
      "                                                                 \n",
      " dense_1846 (Dense)          (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,106\n",
      "Trainable params: 269,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Conv1D, Flatten\n",
    "\n",
    "inputs = Input(shape=(64,1))\n",
    "x = Conv1D(32, 2, padding='same', activation='elu')(inputs)\n",
    "x = Conv1D(64, 2, padding='same', activation='elu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='elu')(x)\n",
    "x = Dense(32, activation='elu')(x)\n",
    "x = Dense(16, activation='elu')(x)\n",
    "x = Dense(2, activation='linear')(x)\n",
    "model = Model(inputs=[inputs], outputs=[x])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "input_Y_train_1dCNN = np_utils.to_categorical(\n",
    "    rifY_train, num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2180, 64)\n"
     ]
    }
   ],
   "source": [
    "print(input_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545/545 [==============================] - 3s 4ms/step - loss: 0.5132 - acc: 0.9124\n",
      "Epoch 2/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.3505 - acc: 0.9330\n",
      "Epoch 3/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.2986 - acc: 0.9427\n",
      "Epoch 4/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.2780 - acc: 0.9440\n",
      "Epoch 5/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.2800 - acc: 0.9422\n",
      "Epoch 6/20\n",
      "545/545 [==============================] - 2s 5ms/step - loss: 0.2434 - acc: 0.9463\n",
      "Epoch 7/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.2389 - acc: 0.9463\n",
      "Epoch 8/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.2289 - acc: 0.9436\n",
      "Epoch 9/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.2038 - acc: 0.9491\n",
      "Epoch 10/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.1899 - acc: 0.9477\n",
      "Epoch 11/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.1780 - acc: 0.9491\n",
      "Epoch 12/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.1769 - acc: 0.9500\n",
      "Epoch 13/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.1786 - acc: 0.9495\n",
      "Epoch 14/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.1687 - acc: 0.9486\n",
      "Epoch 15/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.1629 - acc: 0.9523\n",
      "Epoch 16/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.1640 - acc: 0.9532\n",
      "Epoch 17/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.1757 - acc: 0.9509\n",
      "Epoch 18/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.1676 - acc: 0.9546\n",
      "Epoch 19/20\n",
      "545/545 [==============================] - 2s 5ms/step - loss: 0.1715 - acc: 0.9523\n",
      "Epoch 20/20\n",
      "545/545 [==============================] - 2s 4ms/step - loss: 0.1599 - acc: 0.9546\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "1D CNN\n",
      "--------------------\n",
      "accuracy  0.944954128440367 , f1_score  0.9503311258278145 , auc  0.9446717399012627\n",
      "precision  0.9534883720930233 , sensitivity  0.9471947194719472 , specificity  0.05280528052805278\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=input_X_train,y=input_Y_train_1dCNN,batch_size=4,epochs=20)\n",
    "rifPred=model.predict(input_X_test)\n",
    "rifPred=np.argmax(rifPred,axis=1)\n",
    "# print(rifPred)\n",
    "printResults(\"1D CNN\",input_Y_test,rifPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model5 (GradientBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chandra sekhar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "--------------------\n",
      "accuracy  0.9669724770642202 , f1_score  0.9704918032786886 , auc  0.9657215721572158\n",
      "precision  0.9641693811074918 , sensitivity  0.976897689768977 , specificity  0.02310231023102305\n"
     ]
    }
   ],
   "source": [
    "rifModel5=GradientBoostingClassifier(learning_rate= 0.1, n_estimators= 100)\n",
    "rifModel5.fit(rifX_train,rifY_train)\n",
    "rifPred=rifModel5.predict(rifX_test)\n",
    "printResults(\"GradientBoostingClassifier\",rifY_test,rifPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model6 (Ada Boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chandra sekhar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Classifier forest\n",
      "--------------------\n",
      "accuracy  0.8587155963302753 , f1_score  0.8855869242199109 , auc  0.8429888443389794\n",
      "precision  0.8054054054054054 , sensitivity  0.9834983498349835 , specificity  0.01650165016501648\n"
     ]
    }
   ],
   "source": [
    "rifModel6=AdaBoostClassifier(n_estimators=50, base_estimator=svm.SVC(probability=True, kernel='linear'),learning_rate=1)\n",
    "rifModel6.fit(rifX_train,rifY_train)\n",
    "rifPred=rifModel6.predict(rifX_test)\n",
    "printResults(\"Ada Boost Classifier forest\",rifY_test,rifPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# model7 (XG-Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rifModel7= xgb.XGBClassifier(n_estimators=100, objective='binary:logistic', tree_method='hist', eta=0.1, max_depth=3, enable_categorical=True)\n",
    "# rifModel7.fit(X_train, y_train)\n",
    "\n",
    "# rifModel7.fit(rifX_train,rifY_train)\n",
    "# rifPred=rifModel7.predict(rifX_test)\n",
    "# print(\"XGBoost Classifier\")\n",
    "# print(\"--------------------\")\n",
    "# print(\"accuracy \", accuracy_score(rifY_test,rifPred))\n",
    "# print(\"f1_score \", f1_score(rifY_test,rifPred))\n",
    "# print(\"auc \", roc_auc_score(rifY_test,rifPred))\n",
    "# print(\"precision \",precision_score(rifY_test,rifPred))\n",
    "# print(\"sensitivity \",recall_score(rifY_test,rifPred))\n",
    "# print(\"specificity \",1-recall_score(rifY_test,rifPred))\n",
    "# cm=(confusion_matrix(rifY_test,rifPred))\n",
    "# sns.heatmap(cm,annot=True,cmap=\"Blues\",fmt=\"d\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.xlabel(\"Predicted Label\")\n",
    "# plt.ylabel(\"Actual Label\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# def iterative_xgboost_classifier(num, alpha, rifX_train, rifY_train, rifX_test, rifY_test):\n",
    "#     base_learners = []\n",
    "#     target = rifY_train.copy()\n",
    "\n",
    "#     for _ in range(num):\n",
    "#         xgb_classifier = XGBClassifier(\n",
    "#             n_estimators=1,  # Using a single decision tree as the base learner\n",
    "#             objective='binary:logistic',\n",
    "#             tree_method='hist',\n",
    "#             learning_rate=alpha,\n",
    "#             max_depth=3,\n",
    "#             enable_categorical=True,\n",
    "#             base_score=np.mean(target)  # Initial prediction based on class distribution\n",
    "#         )\n",
    "#         xgb_classifier.fit(rifX_train, target)\n",
    "#         xgb_predictions = xgb_classifier.predict(rifX_train)\n",
    "#         target -= (alpha * xgb_predictions).astype(np.int64)\n",
    "#         base_learners.append(xgb_classifier)\n",
    "\n",
    "#     y_pred = np.zeros_like(rifY_test, dtype=np.float64)\n",
    "\n",
    "#     for xgb_classifier in base_learners:\n",
    "#         y_pred += alpha * xgb_classifier.predict(rifX_test)\n",
    "\n",
    "#     y_pred_class = (y_pred >= 0.5)\n",
    "\n",
    "#     print(\"Iterative XGBoost Classifier with {} Decision Trees and Learning Rate of {}\".format(num, alpha))\n",
    "#     print(\"--------------------\")\n",
    "#     accuracy = accuracy_score(rifY_test, y_pred_class)\n",
    "#     print(f\"Accuracy: {accuracy:.2f}\")\n",
    "#     print(\"f1_score: \", f1_score(rifY_test, y_pred_class))\n",
    "#     print(\"auc: \", roc_auc_score(rifY_test, y_pred_class))\n",
    "#     print(\"precision: \", precision_score(rifY_test, y_pred_class))\n",
    "#     print(\"sensitivity: \", recall_score(rifY_test, y_pred_class))\n",
    "#     print(\"specificity: \", 1 - recall_score(rifY_test, y_pred_class))\n",
    "#     cm = confusion_matrix(rifY_test, y_pred_class)\n",
    "#     sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "#     plt.title(\"Confusion Matrix for XGBoost\")\n",
    "#     plt.xlabel(\"Predicted Label\")\n",
    "#     plt.ylabel(\"Actual Label\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage:\n",
    "# iterative_xgboost_classifier(50, 0.1, rifX_train, rifY_train, rifX_test, rifY_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluating using cross_validation_score with folds=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Random Forest\")\n",
    "# aucScores=cross_val_score(rifModel1, rifX, rifY, cv=30, scoring=\"roc_auc\")\n",
    "# f1Scores = cross_val_score(rifModel1, rifX, rifY, cv=30, scoring='f1')\n",
    "# print(\"Mean f1_score \",f1Scores.mean())\n",
    "# print(\"Mean auc \",aucScores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"SVM\")\n",
    "# aucScores=cross_val_score(rifModel2, rifX, rifY, cv=30, scoring=\"roc_auc\")\n",
    "# f1Scores = cross_val_score(rifModel2, rifX, rifY, cv=30, scoring='f1')\n",
    "# print(\"Mean f1_score \",f1Scores.mean())\n",
    "# print(\"Mean auc \",aucScores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Logistic Regression\")\n",
    "# aucScores=cross_val_score(rifModel3, rifX, rifY, cv=20, scoring=\"roc_auc\")\n",
    "# f1Scores = cross_val_score(rifModel3, rifX, rifY, cv=20, scoring='f1')\n",
    "# print(\"Mean f1_score \",f1Scores.mean())\n",
    "# print(\"Mean auc \",aucScores.mean())\n",
    "# # print(aucScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"BernoulliNB\")\n",
    "# aucScores=cross_val_score(rifModel4, rifX, rifY, cv=30, scoring=\"roc_auc\")\n",
    "# f1Scores = cross_val_score(rifModel4, rifX, rifY, cv=30, scoring='f1')\n",
    "# print(\"Mean f1_score \",f1Scores.mean())\n",
    "# print(\"Mean auc \",aucScores.mean())\n",
    "# # print(aucScores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
